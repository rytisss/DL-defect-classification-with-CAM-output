{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vSHFTBu-1odD",
   "metadata": {
    "id": "vSHFTBu-1odD"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "x81T-y2VmDMR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x81T-y2VmDMR",
    "outputId": "6a1271df-68bd-4bb9-b5b6-247ccb23a1ee"
   },
   "outputs": [],
   "source": [
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fa0b68",
   "metadata": {
    "id": "f4fa0b68"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Conv2D, LeakyReLU, Activation, UpSampling2D, BatchNormalization, AveragePooling2D, concatenate\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41bd19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_name_with_ext(path: str):\n",
    "    file_name_with_ext = os.path.basename(path)\n",
    "    return file_name_with_ext\n",
    "\n",
    "\n",
    "def get_file_name(path: str):\n",
    "    file_name_with_ext = os.path.basename(path)\n",
    "    file_name, file_extension = os.path.splitext(file_name_with_ext)\n",
    "    return file_name\n",
    "\n",
    "\n",
    "def make_directory(output_dir: str):\n",
    "    if not os.path.exists(output_dir):\n",
    "        print('Making output directory: ' + output_dir)\n",
    "        os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7490e0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_training_history(history, number_of_epochs, saver, xbins=10):\n",
    "    # Plot\n",
    "    # training\n",
    "    epochs_ints = range(0, number_of_epoch)\n",
    "    epochs = [str(x) for x in epochs_ints]\n",
    "    \n",
    "    fig = plt.figure(figsize=(6.6, 4.8))\n",
    "    plt.plot(epochs, history.history['binary_accuracy'], 'b--')\n",
    "    plt.plot(epochs, history.history['val_binary_accuracy'], 'b')\n",
    "    plt.plot(epochs, history.history['precision'], 'g--')\n",
    "    plt.plot(epochs, history.history['val_precision'], 'g')\n",
    "    plt.plot(epochs, history.history['recall'], '--', color='orange')\n",
    "    plt.plot(epochs, history.history['val_recall'], color='orange')\n",
    "    plt.axvline(x=saver.best_epoch, color='r')\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticks(ax.get_xticks()[::2])\n",
    "    plt.title('Model accuracy, recall and precision', fontsize=17)\n",
    "    plt.ylabel('accuracy / recall / precision')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train_acc', 'val_acc', 'train_pre', 'val_pre', 'train_rec', 'val_rec', 'best_w'], loc='lower right')\n",
    "    plt.grid(True)\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.show()\n",
    "    \n",
    "    # print values\n",
    "    print('binary_accuracy')\n",
    "    print(history.history['binary_accuracy'])\n",
    "    print('val_binary_accuracy')\n",
    "    print(history.history['val_binary_accuracy'])\n",
    "    print('recall')\n",
    "    print(history.history['recall'])\n",
    "    print('val_recall')\n",
    "    print(history.history['val_recall'])\n",
    "    print('precision')\n",
    "    print(history.history['precision'])\n",
    "    print('val_precision')\n",
    "    print(history.history['val_precision'])\n",
    "\n",
    "    # testing\n",
    "    fig = plt.figure(figsize=(6.6, 4.8))\n",
    "    plt.plot(epochs, history.history['loss'], 'b--')\n",
    "    plt.plot(epochs, history.history['val_loss'], 'g')\n",
    "    plt.axvline(x=saver.best_epoch, color='r')\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticks(ax.get_xticks()[::2])\n",
    "    plt.title('Model loss', fontsize=17)\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['loss', 'val_loss', 'best_w'], loc='upper right')\n",
    "    plt.grid(True)\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.show()\n",
    "    \n",
    "    # print values\n",
    "    print('loss')\n",
    "    print(history.history['loss'])\n",
    "    print('val_loss')\n",
    "    print(history.history['val_loss'])\n",
    "    \n",
    "    print(50 * '-')\n",
    "    print(f'Best Accuracy = {saver.best_acc_score}')\n",
    "    print(f'Best Recall = {saver.best_rec}')\n",
    "    print(f'Best Precision = {saver.best_precision}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3237a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_subplot(fig, rows, cols, pos, name, image, colorspace, min, max):\n",
    "    image_plot = fig.add_subplot(rows, cols, pos)\n",
    "    image_plot.title.set_text(name)\n",
    "    image_plot.title.set_fontsize(17)\n",
    "\n",
    "    if colorspace:\n",
    "        im = plt.imshow(image, cmap=colorspace, vmin=min, vmax=max)\n",
    "        divider = make_axes_locatable(image_plot)\n",
    "        cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "        cb = plt.colorbar(im, cax=cax)\n",
    "    else:\n",
    "        im = plt.imshow(image)\n",
    "        \n",
    "def make_rgb(name, image, save_path):\n",
    "    fig = plt.figure(figsize=(6.6, 4.8))\n",
    "    norm_image = image / 255.\n",
    "    vmin = 0.0\n",
    "    vmax = 1.0\n",
    "    add_subplot(fig, 1, 1, 1, name, norm_image, None, vmin, vmax)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "def make_single_graph(name, image, save_path):\n",
    "    fig = plt.figure(figsize=(6.6, 4.8))\n",
    "    norm_image = image / 255.\n",
    "    colormap = 'jet'\n",
    "    vmin = 0.0\n",
    "    vmax = 1.0\n",
    "    add_subplot(fig, 1, 1, 1, name, norm_image, colormap, vmin, vmax)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "# get all image paths from directory\n",
    "def gather_image_from_dir(input_dir):\n",
    "    image_extensions = ['*.bmp', '*.jpg', '*.png']\n",
    "    image_list = []\n",
    "    for image_extension in image_extensions:\n",
    "        image_list.extend(glob.glob(input_dir + image_extension))\n",
    "    image_list.sort()\n",
    "    return image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b766124a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_fig(image, heatmap, name, output_path):\n",
    "    fig, ax = plt.subplots(figsize=(6.6, 4.8))\n",
    "    ax.imshow(image)\n",
    "    ax.imshow(heatmap, cmap='jet', alpha=0.32)\n",
    "    ax.set_title(name, fontsize=17)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, bbox_inches='tight')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc14848",
   "metadata": {
    "id": "5dc14848"
   },
   "outputs": [],
   "source": [
    "# this code shared in https://stackabuse.com/learning-rate-warmup-with-cosine-decay-in-keras-and-tensorflow/\n",
    "def lr_warmup_cosine_decay(global_step,\n",
    "                           warmup_steps,\n",
    "                           hold = 0,\n",
    "                           total_steps=0,\n",
    "                           start_lr=0.0,\n",
    "                           target_lr=1e-3):\n",
    "    # Cosine decay\n",
    "    learning_rate = 0.5 * target_lr * (1 + np.cos(np.pi * (global_step - warmup_steps - hold) / float(total_steps - warmup_steps - hold)))\n",
    "\n",
    "    # Target LR * progress of warmup (=1 at the final warmup step)\n",
    "    warmup_lr = target_lr * (global_step / warmup_steps)\n",
    "\n",
    "    # Choose between `warmup_lr`, `target_lr` and `learning_rate` based on whether `global_step < warmup_steps` and we're still holding.\n",
    "    # i.e. warm up if we're still warming up and use cosine decayed lr otherwise\n",
    "    if hold > 0:\n",
    "        learning_rate = np.where(global_step > warmup_steps + hold,\n",
    "                                 learning_rate, target_lr)\n",
    "    \n",
    "    learning_rate = np.where(global_step < warmup_steps, warmup_lr, learning_rate)\n",
    "    return learning_rate\n",
    "\n",
    "class WarmupCosineDecay(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, total_steps=0, warmup_steps=0, start_lr=0.0, target_lr=1e-3, hold=0):\n",
    "\n",
    "        super(WarmupCosineDecay, self).__init__()\n",
    "        self.start_lr = start_lr\n",
    "        self.hold = hold\n",
    "        self.total_steps = total_steps\n",
    "        self.global_step = 0\n",
    "        self.target_lr = target_lr\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.lrs = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        self.global_step = self.global_step + 1\n",
    "        lr = model.optimizer.lr.numpy()\n",
    "        self.lrs.append(lr)\n",
    "\n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        lr = lr_warmup_cosine_decay(global_step=self.global_step,\n",
    "                                    total_steps=self.total_steps,\n",
    "                                    warmup_steps=self.warmup_steps,\n",
    "                                    start_lr=self.start_lr,\n",
    "                                    target_lr=self.target_lr,\n",
    "                                    hold=self.hold)\n",
    "        tf.keras.backend.set_value(self.model.optimizer.lr, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ck389MdL3BMz",
   "metadata": {
    "id": "Ck389MdL3BMz"
   },
   "outputs": [],
   "source": [
    "# custom saver\n",
    "class CustomSaver(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, output_dir='', weights_name='best'):\n",
    "        self.best_acc_score = 0.0\n",
    "        self.best_rec = 0.0\n",
    "        self.best_precision = 0.0\n",
    "        self.best_epoch = 0\n",
    "        self.__output_dir = output_dir\n",
    "        # make output directory\n",
    "        if not os.path.exists(self.__output_dir):\n",
    "            os.makedirs(self.__output_dir)\n",
    "        self.__weights_name = weights_name\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # also save if validation error is smallest\n",
    "        if 'val_binary_accuracy' in logs.keys():\n",
    "            val_acc = logs['val_binary_accuracy']\n",
    "            if val_acc > self.best_acc_score:\n",
    "                self.best_acc_score = val_acc\n",
    "                self.best_rec = logs['val_recall']\n",
    "                self.best_precision = logs['val_precision']\n",
    "                self.best_epoch = epoch\n",
    "                output_path = self.__output_dir + '/' + self.__weights_name + '.hdf5'\n",
    "                print(f'New best weights found! Saving to {output_path}')\n",
    "                self.model.save(output_path)\n",
    "        else:\n",
    "            print('Key val_binary_accuracy does not exist!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bc4b60",
   "metadata": {
    "id": "24bc4b60"
   },
   "outputs": [],
   "source": [
    "def effiecientNetV2B0Classifier(input_size=(128, 128, 3), last_stage_out=False, add_aspp=False, weights_path=None):\n",
    "    inputs = tf.keras.Input(shape=input_size)\n",
    "    x = tf.keras.applications.efficientnet_v2.EfficientNetV2B0(include_top=False,\n",
    "                                                    weights='imagenet',\n",
    "                                                    input_tensor=inputs)\n",
    "    if last_stage_out:\n",
    "        x = x.get_layer('block6a_expand_activation').output\n",
    "    else:\n",
    "        x = x.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    model = tf.keras.Model(inputs, x)\n",
    "    model.compile(loss=tf.keras.losses.BinaryFocalCrossentropy(),\n",
    "                  optimizer=AdamW(learning_rate=1e-3),\n",
    "                  metrics=[tf.keras.metrics.BinaryAccuracy(threshold=0.5),\n",
    "                           tf.keras.metrics.Precision(thresholds=0.5),\n",
    "                           tf.keras.metrics.Recall(thresholds=0.5)])\n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d908c31",
   "metadata": {
    "id": "2d908c31"
   },
   "outputs": [],
   "source": [
    "def convnextTinyClassifier(input_size=(128, 128, 3), last_stage_out=False, add_aspp=False, weights_path=None):\n",
    "    inputs = tf.keras.Input(shape=input_size)\n",
    "    x = tf.keras.applications.convnext.ConvNeXtTiny(include_top=False,\n",
    "                                                    weights='imagenet',\n",
    "                                                    input_tensor=inputs)\n",
    "    \n",
    "    if last_stage_out:\n",
    "        x = x.get_layer('convnext_tiny_stage_2_block_8_identity').output\n",
    "    else:\n",
    "        x = x.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    model = tf.keras.Model(inputs, x)\n",
    "    model.compile(loss=tf.keras.losses.BinaryFocalCrossentropy(),\n",
    "                  optimizer=AdamW(learning_rate=1e-3),\n",
    "                  metrics=[tf.keras.metrics.BinaryAccuracy(threshold=0.5),\n",
    "                           tf.keras.metrics.Precision(thresholds=0.5),\n",
    "                           tf.keras.metrics.Recall(thresholds=0.5)])\n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e427ced",
   "metadata": {
    "id": "7e427ced"
   },
   "outputs": [],
   "source": [
    "def mobileNetV3Classifier(input_size=(128, 128, 3), last_stage_out=False, add_aspp=False, weights_path=None):\n",
    "    inputs = tf.keras.Input(shape=input_size)\n",
    "    x = tf.keras.applications.MobileNetV3Large(include_top=False,\n",
    "                                                weights='imagenet',\n",
    "                                                input_tensor=inputs)\n",
    "    if last_stage_out:\n",
    "        x = x.layers[193].output\n",
    "    else:\n",
    "        x = x.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    model = tf.keras.Model(inputs, x)\n",
    "    model.compile(loss=tf.keras.losses.BinaryFocalCrossentropy(),\n",
    "                  optimizer=AdamW(learning_rate=1e-3),\n",
    "                  metrics=[tf.keras.metrics.BinaryAccuracy(threshold=0.5),\n",
    "                           tf.keras.metrics.Precision(thresholds=0.5),\n",
    "                           tf.keras.metrics.Recall(thresholds=0.5)])\n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xq5Hqy6xzNFq",
   "metadata": {
    "id": "xq5Hqy6xzNFq"
   },
   "outputs": [],
   "source": [
    "# Data, training parameters and output cell\n",
    "# Input image information\n",
    "input_width = 752\n",
    "input_height = 480\n",
    "input_channels = 3\n",
    "# batch size. How many samples you want to feed in one iteration?\n",
    "batch_size = 4\n",
    "# number_of_epoch. How many epochs you want to train?\n",
    "number_of_epoch = 50\n",
    "# learning rate\n",
    "learning_rate=0.0001\n",
    "# training percentage until full learning rate [0.0;1.0]\n",
    "warmup_percentage=0.15\n",
    "# weights output directory\n",
    "output_dir = 'Oliena_weights/convnext_4down/'\n",
    "# output weights name\n",
    "output_weights_name = 'convnext_4down'\n",
    "\n",
    "image_output = output_dir + 'images/'\n",
    "make_directory(image_output)\n",
    "\n",
    "cam_output = output_dir + 'cam/'\n",
    "make_directory(cam_output)\n",
    "\n",
    "heatmap_output = output_dir + 'heatmap/'\n",
    "make_directory(heatmap_output)\n",
    "\n",
    "# data directories\n",
    "training_data_dir = 'Oliena/train/'\n",
    "testing_data_dir = 'Oliena/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_ouoq_rH01T3",
   "metadata": {
    "id": "_ouoq_rH01T3"
   },
   "outputs": [],
   "source": [
    "# DATA AUGMENTATION\n",
    "# Augmentation pipeline\n",
    "def transform(image):\n",
    "    aug = A.Compose([\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.2),\n",
    "        A.RandomGamma(p=0.2),\n",
    "        A.ShiftScaleRotate(p=0.2,\n",
    "                           shift_limit=[-0.1, 0.1],\n",
    "                           scale_limit=[-0.05,0.05],\n",
    "                           rotate_limit=[-5,5])\n",
    "    ])\n",
    "    return aug(image=image)['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e667b5a9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e667b5a9",
    "outputId": "f2b5b5ae-12d3-4bb8-fb7c-e46cfaa66273"
   },
   "outputs": [],
   "source": [
    "# data generators\n",
    "train_image_generator = ImageDataGenerator(preprocessing_function=transform)\n",
    "\n",
    "train_generator = train_image_generator.flow_from_directory(\n",
    "    training_data_dir,\n",
    "    target_size=(input_height, input_width),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    color_mode='rgb',\n",
    "    class_mode='binary')\n",
    "\n",
    "test_image_generator = ImageDataGenerator()\n",
    "\n",
    "test_generator = test_image_generator.flow_from_directory(\n",
    "    testing_data_dir, \n",
    "    target_size=(input_height, input_width),\n",
    "    batch_size=batch_size,\n",
    "    color_mode='rgb',\n",
    "    class_mode='binary') # set as validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saH4TMEJ1dXS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "saH4TMEJ1dXS",
    "outputId": "5f3c6f7c-9ae4-493d-f8bd-9c592b301ebe"
   },
   "outputs": [],
   "source": [
    "# MODEL\n",
    "model = convnextTinyClassifier(input_size=(input_height, input_width, input_channels), last_stage_out=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "D2uAnOY61jC1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D2uAnOY61jC1",
    "outputId": "c595ace9-792c-46ff-cec2-c0740f74b112"
   },
   "outputs": [],
   "source": [
    "# warmup and cosine schedule\n",
    "total_steps = train_generator.samples/batch_size*number_of_epoch\n",
    "# defined number of the steps\n",
    "warmup_steps = int(warmup_percentage*total_steps)\n",
    "\n",
    "print(f'Warmup steps: {warmup_steps}')\n",
    "\n",
    "schedule = WarmupCosineDecay(start_lr=0.0,\n",
    "                             target_lr=learning_rate,\n",
    "                             warmup_steps=warmup_steps,\n",
    "                             total_steps=total_steps,\n",
    "                             hold=warmup_steps)\n",
    "\n",
    "# custom saver serves as function to save the best performing weights\n",
    "saver = CustomSaver(output_dir=output_dir, weights_name=output_weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68b7ea35muv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f68b7ea35muv",
    "outputId": "8ccbbbc9-2452-4d80-c142-63fd9fed56ab",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch = train_generator.samples // batch_size,\n",
    "    validation_data = test_generator, \n",
    "    validation_steps = test_generator.samples // batch_size,\n",
    "    epochs = number_of_epoch,\n",
    "    callbacks=[schedule, saver],\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c5ff42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best weights\n",
    "model.load_weights(output_dir + output_weights_name + '.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989c1681",
   "metadata": {
    "id": "989c1681"
   },
   "outputs": [],
   "source": [
    "x = model.layers[-3].output\n",
    "print(f'Output shape before average pooling: {x.shape}')\n",
    "weights = tf.expand_dims(model.layers[-1].get_weights()[0][:,0], 0)\n",
    "x = tf.keras.layers.dot([x, weights], axes=(3, 1))\n",
    "print(f'Output shape of expanded weights: {weights.shape}')\n",
    "print(f'Output after multiplication: {x.shape}')\n",
    "# make multihead output\n",
    "multi_head_model = tf.keras.Model(inputs=model.input, \n",
    "        outputs=(x, model.layers[-1].output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad0f157",
   "metadata": {
    "id": "1ad0f157"
   },
   "outputs": [],
   "source": [
    "# get all image paths from directory\n",
    "def gather_image_from_dir(input_dir):\n",
    "    image_extensions = ['*.bmp', '*.jpg', '*.png']\n",
    "    image_list = []\n",
    "    for image_extension in image_extensions:\n",
    "        image_list.extend(glob.glob(input_dir + image_extension))\n",
    "    image_list.sort()\n",
    "    return image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd9e51d",
   "metadata": {
    "id": "8fd9e51d"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('agg') # let matplotlib save more (>370) images\n",
    "\n",
    "image_paths = gather_image_from_dir(testing_data_dir + '1/')\n",
    "print(f'Found {len(image_paths)} images')\n",
    "# lets predict\n",
    "for i, image_path in enumerate(image_paths):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_COLOR) # no need to switch channels, it is actually greyscale\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (model.input.shape[2], model.input.shape[1])) # no need if cropped\n",
    "    image_name = get_file_name(image_path)\n",
    "    \n",
    "    # prepocess image\n",
    "    # preprocess\n",
    "    image_norm = image\n",
    "    image_norm = np.reshape(image_norm, image_norm.shape + (1,))\n",
    "    image_norm = np.reshape(image_norm, (1,) + image_norm.shape)\n",
    "    \n",
    "    #prediction = model.predict(image_norm)\n",
    "    # Get the output of last convolutional layer and prediction\n",
    "    last_conv_output, prediction = multi_head_model.predict(image_norm)\n",
    "    last_conv_output = last_conv_output[0,:,:]# we have only one image, so take the first one\n",
    "    last_conv_output_scaled = cv2.resize(last_conv_output, (model.input.shape[2], model.input.shape[1]))\n",
    "    \n",
    "    draw_fig(image, last_conv_output_scaled, 'image+defectCAM', cam_output + image_name + '_defectCAM_superpos.png')\n",
    "    \n",
    "    print(f'{image_name} {last_conv_output_scaled.shape} {prediction}')\n",
    "    print()\n",
    "    make_rgb('image', image, image_output + image_name + '_rgb.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119b3a1b",
   "metadata": {
    "id": "119b3a1b"
   },
   "outputs": [],
   "source": [
    "# for mask output\n",
    "output_image_dir = 'Oliena/oliena-SingleDefectMask/test/'\n",
    "image_paths = gather_image_from_dir(output_image_dir + 'images/')\n",
    "print(f'Found {len(image_paths)} images')\n",
    "masks_paths = gather_image_from_dir(output_image_dir + 'masks/')\n",
    "print(f'Found {len(masks_paths)} labels')\n",
    "\n",
    "prediction_output = output_dir + 'prediction/'\n",
    "prediction_image_output = prediction_output + 'image/'\n",
    "make_directory(prediction_image_output)\n",
    "prediction_label_output = prediction_output + 'label/'\n",
    "make_directory(prediction_label_output)\n",
    "prediction_model_output = prediction_output + 'prediction/'\n",
    "make_directory(prediction_model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659092e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets predict\n",
    "for i, image_path in enumerate(image_paths):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_COLOR) # no need to switch channels, it is actually greyscale\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (model.input.shape[2], model.input.shape[1])) # no need if cropped\n",
    "    image_name = get_file_name(image_path)\n",
    "    \n",
    "    label = cv2.imread(masks_paths[i], cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # prepocess image\n",
    "    # preprocess\n",
    "    image_norm = image\n",
    "    image_norm = np.reshape(image_norm, image_norm.shape + (1,))\n",
    "    image_norm = np.reshape(image_norm, (1,) + image_norm.shape)\n",
    "    \n",
    "    #prediction = model.predict(image_norm)\n",
    "    # Get the output of last convolutional layer and prediction\n",
    "    last_conv_output, prediction = multi_head_model.predict(image_norm)\n",
    "    prediction = np.squeeze(prediction)\n",
    "    last_conv_output = last_conv_output[0,:,:]# we have only one image, so take the first one\n",
    "    last_conv_output_scaled = cv2.resize(last_conv_output, (model.input.shape[2], model.input.shape[1]))\n",
    "    # Normalize the image\n",
    "    last_conv_output_scaled_normalized = cv2.normalize(last_conv_output_scaled, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    \n",
    "    cv2.imwrite(prediction_image_output + image_name + '.png', image)\n",
    "    cv2.imwrite(prediction_label_output + image_name + '.png', label)\n",
    "    \n",
    "    if prediction >= 0.5:\n",
    "        mask = last_conv_output_scaled_normalized\n",
    "    else:\n",
    "        mask = np.zeros(shape=(model.input.shape[1], model.input.shape[2]), dtype=np.uint8)\n",
    "    cv2.imwrite(prediction_model_output + image_name + '.png', mask)\n",
    "    \n",
    "    #draw_fig(image, last_conv_output_scaled, 'image+defectCAM', cam_output + image_name + '_defectCAM_superpos.png')\n",
    "    print(f'{image_name} {last_conv_output_scaled.shape} {prediction}')\n",
    "    #make_rgb('image', image, image_output + image_name + '_rgb.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f54edd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
